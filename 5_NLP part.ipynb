{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I will use NLP (pretrained RoBERTa model) to estimate the missing ratings of about ~2500 observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from simpletransformers.classification import ClassificationModel\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is not the main focus of this project, I am using the library called simple transformers, which allows me to get decent results fast.\n",
    "\n",
    "The library accepts a dataframe with two columns ('text' and 'label'), preprocesses it and fits to base RoBERTA (transfer learning). Our problem is essentialy a multiclass classification problem with 5 classes. One major problem in our data is the class imbalance, as was seen earlier. To solve this issue, I use weights - I downweight the 5 star reviews quite heavily, while I upweight some of the less common classes - this allows me to improve the model results significantly. I did most of the coding on the Kaggle kernels, since my PC does not support CUDA, so the code here is just a general idea for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'E:\\parsing project\\merged_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>num_rating</th>\n",
       "      <th>for_nlp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of my favorites!!! i don't care when i wea...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i love it! i pondered on it for awhile. it’s e...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>love this and the travel spray bottle is so co...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i love the fragrance which is light and not ov...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pretty fragrance i get a lot of compliments on...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39363</th>\n",
       "      <td>i wear this fragrance, especially in the sprin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39364</th>\n",
       "      <td>i love love love love love this perfume. when ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39365</th>\n",
       "      <td>burbbery weekend is a wonderful strong scent w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39366</th>\n",
       "      <td>this fragrance smell so good it's such a matur...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39367</th>\n",
       "      <td>it's very subtle....almost disappears on ya!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39368 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             review_text  num_rating  for_nlp\n",
       "0      one of my favorites!!! i don't care when i wea...         5.0        0\n",
       "1      i love it! i pondered on it for awhile. it’s e...         5.0        0\n",
       "2      love this and the travel spray bottle is so co...         5.0        0\n",
       "3      i love the fragrance which is light and not ov...         5.0        0\n",
       "4      pretty fragrance i get a lot of compliments on...         5.0        0\n",
       "...                                                  ...         ...      ...\n",
       "39363  i wear this fragrance, especially in the sprin...         NaN        1\n",
       "39364  i love love love love love this perfume. when ...         NaN        1\n",
       "39365  burbbery weekend is a wonderful strong scent w...         NaN        1\n",
       "39366  this fragrance smell so good it's such a matur...         NaN        1\n",
       "39367       it's very subtle....almost disappears on ya!         NaN        1\n",
       "\n",
       "[39368 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['review_text', 'num_rating', 'for_nlp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_index = df[df['for_nlp'] == 1].index\n",
    "rest_index =df[df['for_nlp'] == 0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval = df.loc[nlp_index][['review_text', 'num_rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.loc[rest_index][['review_text', 'num_rating']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the ratings so they are between 0 and 4 - necessary for model to work\n",
    "data['num_rating'] = data['num_rating'].astype(int) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>num_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>absolutely worth the hype - pineapple and soft...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           review_text  num_rating\n",
       "424  absolutely worth the hype - pineapple and soft...           4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.rename(columns = {'review_text': 'text', 'num_rating': 'labels'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['text']\n",
    "y = data['labels']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle = True, stratify = y)\n",
    "#stratify and unite them again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(X_train).merge(pd.DataFrame(y_train), left_index = True, right_index = True)\n",
    "test = pd.DataFrame(X_test).merge(pd.DataFrame(y_test), left_index = True, right_index = True)\n",
    "\n",
    "#missing rating stars\n",
    "predict_this = df.loc[nlp_index]['review_text']#.apply(lambda x: [str(x)])\n",
    "predict_this = predict_this.reset_index(drop = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will take a long time to train if you are using cpu. Since my graphics card did not support CUDA, I had to use kaggle kernels to train this model. The code below is greyed out intentionally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'roberta.pooler.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#model = ClassificationModel('roberta', 'roberta-base', num_labels=5, weight = [1, 1.8, 1.15, 0.5, 0.03], args = {'overwrite_output_dir': True, 'ngpu': 1, 'num_train_epochs':4, 'use_early_stopping': True, 'reprocess_input_data': True, 'early_stopping_delta' : 0.01})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.train_model(train) -> retrain on the whole dataset after calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "\n",
    "def f1_multiclass(labels, preds):\n",
    "    return f1_score(labels, preds, average='micro')\n",
    "    \n",
    "result, model_outputs, wrong_predictions = model.eval_model(test, f1=f1_multiclass, acc=accuracy_score)\n",
    "\n",
    "#0.87 f1 multiclass score with given weights - 0.79 without weights"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then use this model to predict (model.predict) the missing data. I obtain the following predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.read_csv(r'E:\\parsing project\\preds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have one erroneous row - happened by accident\n",
    "predictions = predictions.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions['preds'] = (predictions['preds'] + 1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1      76\n",
       "2       9\n",
       "3      51\n",
       "4     125\n",
       "5    2241\n",
       "Name: preds, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions['preds'].value_counts().sort_index() "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can notice the importance of weights here - if we don't use weights, our model learns to predict class 5 only and ignore rest of the classes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, the predictions are quite decent, although they are not perfect (for example, the sentiment can be positive, but the predicted rating is low - happens mostly to complex sentences). It is worth mentioning, that the data has some noisy reviews as well - although it is possible to fix these cases manually is small datasets, it wouldnt be possible in big productions with millions of reviews. I did not fix these cases manually, thus our final data has some noise. However, most of the reviews in the data should display the true valuation of the product."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Match them back:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[nlp_index, 'num_rating'] = predictions['preds'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['num_rating'].isna().sum() # no missing ratings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('merged_after_nlp.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "16f5b46f222e2a3e8d4adbf7141cae37b71ed37616e60735fa5d1164a1bc3ada"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
